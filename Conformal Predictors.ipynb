{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CP_Diff_Class(X,Y,xt):\n",
    "    if len(X) == len(Y): #check if Samples and labels have same length\n",
    "        labels = list(set(Y)) #Finding out the distinct Labels to assign\n",
    "        \n",
    "        predicted_labels = [] #will store the predicted label\n",
    "        pred_label_conformity_score = []  #stores higher pvalue scores\n",
    "        other_label_conformity_score = [] #stores lower pvalue scores\n",
    "        \n",
    "        for b in range(len(xt)): #Looping through all the test samples\n",
    "            test = xt[b]  #taking 1 test sample at a time\n",
    "            \n",
    "            scores_for_both_classes = [] #stores the pvalues (Here for -1 and +1)\n",
    "            return_labels = [] #consists of labels (Here -1,+1)\n",
    "            \n",
    "            for k in range(len(labels)): #Loop to iterate through labels (Here +1 and -1)\n",
    "                    x =  X.copy() #Create Copy of X-train\n",
    "                    y =  Y.copy() #Create Copy of Y-train\n",
    "                    conformity_scores = [] # to store nearest distance to different class\n",
    "                    distance_array = [] # to store all distances\n",
    "\n",
    "                    x.append(test) # Create an Augmented Training Set\n",
    "                    y.append(labels[k]) #Create Augmented set using a label to consider\n",
    "\n",
    "                    for i in range(len(x)): #loop to find distances from different classes\n",
    "                        a1 = x[i][0] #take point 1 from tuple of (point1,point2)\n",
    "                        b1 = x[i][1] #take point 2 from tuple of (point1,point2)\n",
    "\n",
    "                        for j in range(len(x)): #looping through all the points\n",
    "                            if j!=i:  # check its not the same sample\n",
    "                                if y[i] != y[j]: #check if it has a different label\n",
    "                                    a2 = x[j][0]\n",
    "                                    b2 = x[j][1]\n",
    "                                    t1 = (a1-a2)**2\n",
    "                                    t2 = (b1-b2)**2\n",
    "                                    d = np.sqrt(t1+t2) # calculations to find Euclidean Distance\n",
    "                                    distance_array.append(d) #append each distance to different class in this array\n",
    "                                    \n",
    "                        conformity_scores.append(min(distance_array)) #append nearest Distance to array using \"min\"\n",
    "                        distance_array.clear() #reset distance array to store next set of distances\n",
    "                    \n",
    "                    #After this loop we have all the nearest distances to different class in conformity_scores array\n",
    "                    \n",
    "                    test_sample_score = conformity_scores[len(x)-1] #take the test sample's score in a variable\n",
    "                    conformity_scores.sort(reverse=True) #Sort in Descending Order to calculate rank pessimistically\n",
    "                    \n",
    "                    for rank in range(len(conformity_scores)): # loop to find rank\n",
    "                        if conformity_scores[rank]==test_sample_score:\n",
    "                            break\n",
    "\n",
    "                    rank = len(x)-rank #Logic for Pessimistic Approach to find Rank\n",
    "                    p_value = (rank)/len(x) #formula for p_value\n",
    "                    \n",
    "                    scores_for_both_classes.append(p_value) #stores pvalue for all the labels (Here +1 and -1)\n",
    "                    return_labels.append(labels[k]) #stores corresponding labels\n",
    "\n",
    "            index_max = np.argmax(scores_for_both_classes) #getting index of higher pvalue\n",
    "            index_min = np.argmin(scores_for_both_classes) #getting index of lower pvalue\n",
    "            \n",
    "            predicted_labels.append(return_labels[index_max])  #stores predicted label\n",
    "            pred_label_conformity_score.append(scores_for_both_classes[index_max]) #stores higher pvalue\n",
    "            other_label_conformity_score.append(scores_for_both_classes[index_min]) #stores lower pvalue\n",
    "            \n",
    "        return predicted_labels,pred_label_conformity_score,other_label_conformity_score\n",
    "    else:\n",
    "        return \"Error:Size of Samples and Labels mismatched\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = [(0,3),(2,2),(3,3),(-1,1),(-1,-1),(0,1)]\n",
    "y = [+1,+1,+1,-1,-1,-1]\n",
    "xt = [(-1,-1),(0,0),(0,1),(2,1),(2,3),(3,3)]\n",
    "# CP_Diff_Class(x,y,xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CP_DiffBySame(X,Y,xt):\n",
    "    if len(X) == len(Y): #check if Samples and labels have same length\n",
    "        labels = list(set(Y)) #Finding out the distinct Labels to assign\n",
    "        \n",
    "        predicted_labels = [] #will store the predicted label\n",
    "        pred_label_conformity_score = []  #stores higher pvalue scores\n",
    "        other_label_conformity_score = [] #stores lower pvalue scores\n",
    "\n",
    "        for b in range(len(xt)): #Looping through all the test samples\n",
    "            test = xt[b]  #taking 1 test sample at a time\n",
    "            \n",
    "            scores_for_both_classes = [] #stores the pvalues (Here for -1 and +1)\n",
    "            return_labels = [] #consists of labels (Here -1,+1)\n",
    "            \n",
    "            for k in range(len(labels)): #Loop to iterate through labels (Here +1 and -1)\n",
    "                    x =  X.copy() #Create Copy of X-train\n",
    "                    y =  Y.copy() #Create Copy of Y-train\n",
    "                    \n",
    "                    diff_class = [] #to store nearest distances to different classes\n",
    "                    same_class = [] #to store nearest distances to same classes\n",
    "                    \n",
    "                    conformity_scores = [] #to store diff/same class calculations\n",
    "\n",
    "                    x.append(test) # Create an Augmented Training Set\n",
    "                    y.append(labels[k]) #Create Augmented set using a label to consider\n",
    "\n",
    "                    for i in range(len(x)): #loop to find distances from different classes\n",
    "                        a1 = x[i][0] #take point 1 from tuple of (point1,point2)\n",
    "                        b1 = x[i][1] #take point 2 from tuple of (point1,point2)\n",
    "                        distance_array1 = [] #to store all distances to different class\n",
    "                        distance_array2 = [] #to store all distances to different class\n",
    "                        for j in range(len(x)): #looping through all the points\n",
    "                            if j!=i: #check its not the same point\n",
    "                                a2 = x[j][0]\n",
    "                                b2 = x[j][1]\n",
    "                                t1 = (a1-a2)**2\n",
    "                                t2 = (b1-b2)**2\n",
    "                                d = np.sqrt(t1+t2) # formula to find Euclidean Distances   \n",
    "                                if y[i] != y[j]: #check if it is different class\n",
    "                                    distance_array1.append(d) #storing Different Classes Distances\n",
    "                                else: #else it is same class\n",
    "                                    distance_array2.append(d) #storing Same Classes Distances\n",
    "\n",
    "                        diff_class.append(min(distance_array1)) #stores Nearest Distance to Different Class\n",
    "                        same_class.append(min(distance_array2)) #stores Nearest Distance to Same Class\n",
    "\n",
    "                    for r in range(len(same_class)):  #remove zero values\n",
    "                        if same_class[r] == 0:\n",
    "                            same_class[r] = 0.00001\n",
    "                            \n",
    "                    #Logic to calculate find Diff/Same Scores\n",
    "                    conformity_scores = [ p/q for p,q in zip(diff_class,same_class) ]   \n",
    "\n",
    "                    test_sample_score = conformity_scores[len(x)-1]\n",
    "                    conformity_scores.sort(reverse=True) #Sort in Descending Order to Calculate rank Pessimistically\n",
    "                    \n",
    "                    for rank in range(len(x)): #Loop to find the rank\n",
    "                        if conformity_scores[rank]==test_sample_score:\n",
    "                            break\n",
    "\n",
    "                    rank = len(x)-rank #Logic for Pessimistic Approach to find Rank\n",
    "                    p_value = (rank)/len(x) #formula for p_value\n",
    "                    \n",
    "                    scores_for_both_classes.append(p_value) #stores pvalue for all the labels (Here +1 and -1)\n",
    "                    return_labels.append(labels[k]) #stores corresponding labels\n",
    "\n",
    "            index_max = np.argmax(scores_for_both_classes) #getting index of higher pvalue\n",
    "            index_min = np.argmin(scores_for_both_classes) #getting index of lower pvalue\n",
    "            \n",
    "            predicted_labels.append(return_labels[index_max])  #stores predicted label\n",
    "            pred_label_conformity_score.append(scores_for_both_classes[index_max]) #stores higher pvalue\n",
    "            other_label_conformity_score.append(scores_for_both_classes[index_min]) #stores lower pvalue\n",
    " \n",
    "        return predicted_labels,pred_label_conformity_score,other_label_conformity_score\n",
    "    else:\n",
    "        return \"Error:Size of Samples and Labels mismatched\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = [(0,3),(2,2),(3,3),(-1,1),(-1,-1),(0,1)]\n",
    "y = [+1,+1,+1,-1,-1,-1]\n",
    "xt = [(-1,-1),(0,0),(0,2),(2,1),(2,3),(3,3),(0,-2),(-2,0)]\n",
    "# CP_DiffBySame(x,y,xt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program to Create Artificial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "random.seed(3)\n",
    "\n",
    "x_train_positive=[]\n",
    "x_m = 2\n",
    "y_m = 3\n",
    "s = 1 \n",
    "\n",
    "for i in range(60):\n",
    "        x1 = x_m + s*np.random.normal(0,1)\n",
    "        x2 = y_m + s*np.random.normal(0,1)\n",
    "        x_train_positive.append((x1,x2))\n",
    "\n",
    "x_train_negative=[]\n",
    "x_m = 0\n",
    "y_m = 0\n",
    "s = 2\n",
    "for i in range(70):\n",
    "        x1 = x_m + s*np.random.normal(0,1)\n",
    "        x2 = y_m + s*np.random.normal(0,1)\n",
    "        x_train_negative.append((x1,x2))\n",
    "    \n",
    "x_test_positive=[]\n",
    "x_m = 2\n",
    "y_m = 3\n",
    "s = 1 \n",
    "for i in range(70):\n",
    "        x1 = x_m + s*np.random.normal(0,1)\n",
    "        x2 = y_m + s*np.random.normal(0,1)\n",
    "        x_test_positive.append((x1,x2))\n",
    "\n",
    "x_test_negative=[]\n",
    "x_m = 0\n",
    "y_m = 0\n",
    "s = 2\n",
    "for i in range(60):\n",
    "        x1 = x_m + s*np.random.normal(0,1)\n",
    "        x2 = y_m + s*np.random.normal(0,1)\n",
    "        x_test_negative.append((x1,x2))\n",
    "        \n",
    "\n",
    "import random\n",
    "x_train = x_train_positive + x_train_negative\n",
    "y_train = len(x_train_positive)*[+1] + len(x_train_negative)*[-1]\n",
    "t = list(zip(x_train, y_train))\n",
    "random.shuffle(t)\n",
    "x_train, y_train = zip(*t)\n",
    "#Here our x_train and y_train Data is ready\n",
    "\n",
    "x_test = x_test_positive + x_test_negative\n",
    "y_test = len(x_test_positive)*[+1] + len(x_test_negative)*[-1]\n",
    "t = list(zip(x_test, y_test))\n",
    "random.shuffle(t)\n",
    "x_test, y_test = zip(*t)\n",
    "#Here our x_test and y_test Data is ready\n",
    "\n",
    "x_train = list(x_train)\n",
    "y_train = list(y_train)\n",
    "x_test = list(x_test)\n",
    "y_test = list(y_test)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using Different Class is:  83.84615384615385\n",
      "Accuracy using Diff/Same Class is:  84.61538461538461\n"
     ]
    }
   ],
   "source": [
    "def Accuracy(y_pred,y_test):\n",
    "    count = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if(y_pred[i]==y_test[i]):\n",
    "            count+=1\n",
    "    return (count/len(y_pred))*100\n",
    "\n",
    "out1 = CP_Diff_Class(x_train,y_train,x_test)\n",
    "y_pred = out1[0]\n",
    "A = Accuracy(y_pred,y_test)\n",
    "print(\"Accuracy using Different Class is: \",A)\n",
    "\n",
    "out2 = CP_DiffBySame(x_train,y_train,x_test)\n",
    "y_pred = out2[0]\n",
    "A = Accuracy(y_pred,y_test)\n",
    "print(\"Accuracy using Diff/Same Class is: \",A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validity for Different Class method is:  0.4846153846153844\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "out1 = CP_Diff_Class(x_train,y_train,x_test)\n",
    "y_pred = out1[0]\n",
    "p_values = out1[1]\n",
    "other_pvalues = out1[2]\n",
    "p_true = [] #True label of Y's Pvalue\n",
    "for i in range(len(y_pred)):\n",
    "    if y_test[i] == y_pred[i]:\n",
    "        p_true.append(p_values[i])   \n",
    "    else:\n",
    "        p_true.append(other_pvalues[i])\n",
    "\n",
    "v = sum(p_true)/len(p_true)\n",
    "print(\"Validity for Different Class method is: \",v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validity for Diff/Same Class method is:  0.5120963006459189\n"
     ]
    }
   ],
   "source": [
    "out2 = CP_DiffBySame(x_train,y_train,x_test)\n",
    "y_pred = out2[0]\n",
    "p_values = out2[1]\n",
    "other_pvalues = out1[2]\n",
    "p_true = [] #True label of Y's Pvalue\n",
    "for i in range(len(y_pred)):\n",
    "    if y_test[i] == y_pred[i]:\n",
    "        p_true.append(p_values[i])\n",
    "    else:\n",
    "        p_true.append(other_pvalues[i])\n",
    "\n",
    "v = sum(p_true)/len(p_true)\n",
    "print(\"Validity for Diff/Same Class method is: \",v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficiency Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efficiency for Different Class method is:  0.637874339401057\n",
      "Efficiency for Diff/Same Class method is:  0.5918966529653554\n"
     ]
    }
   ],
   "source": [
    "out1 = CP_Diff_Class(x_train,y_train,x_test)\n",
    "pvalues = out1[1] \n",
    "other_pvalues = out1[2]\n",
    "s = []\n",
    "for (a,b) in zip(pvalues,other_pvalues):\n",
    "    s.append(a+b)\n",
    "sum_pvalues = sum(s)\n",
    "length = len(pvalues)\n",
    "Efficiency = sum_pvalues/length\n",
    "print(\"Efficiency for Different Class method is: \",Efficiency)\n",
    "\n",
    "out2 = CP_DiffBySame(x_train,y_train,x_test)\n",
    "pvalues = out2[1] \n",
    "other_pvalues = out2[2]\n",
    "s = []\n",
    "for (a,b) in zip(pvalues,other_pvalues):\n",
    "    s.append(a+b)\n",
    "sum_pvalues = sum(s)\n",
    "length = len(pvalues)\n",
    "Efficiency = sum_pvalues/length\n",
    "print(\"Efficiency for Diff/Same Class method is: \",Efficiency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Set Seed Value testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "set_seeds = []\n",
    "Acc_1 = []\n",
    "Acc_2 = []\n",
    "Val_1 = []\n",
    "Val_2 = []\n",
    "Eff_1 = []\n",
    "Eff_2 = []\n",
    "\n",
    "for it in range(10):\n",
    "    random.seed(it)\n",
    "    set_seeds.append(it)\n",
    "    x_train_positive=[]\n",
    "    x_m = 2\n",
    "    y_m = 3\n",
    "    s = 1 \n",
    "\n",
    "    for i in range(60):\n",
    "            x1 = x_m + s*np.random.normal(0,1)\n",
    "            x2 = y_m + s*np.random.normal(0,1)\n",
    "            x_train_positive.append((x1,x2))\n",
    "\n",
    "    x_train_negative=[]\n",
    "    x_m = 0\n",
    "    y_m = 0\n",
    "    s = 2\n",
    "    for i in range(70):\n",
    "            x1 = x_m + s*np.random.normal(0,1)\n",
    "            x2 = y_m + s*np.random.normal(0,1)\n",
    "            x_train_negative.append((x1,x2))\n",
    "\n",
    "    x_test_positive=[]\n",
    "    x_m = 2\n",
    "    y_m = 3\n",
    "    s = 1 \n",
    "    for i in range(70):\n",
    "            x1 = x_m + s*np.random.normal(0,1)\n",
    "            x2 = y_m + s*np.random.normal(0,1)\n",
    "            x_test_positive.append((x1,x2))\n",
    "\n",
    "    x_test_negative=[]\n",
    "    x_m = 0\n",
    "    y_m = 0\n",
    "    s = 2\n",
    "    for i in range(60):\n",
    "            x1 = x_m + s*np.random.normal(0,1)\n",
    "            x2 = y_m + s*np.random.normal(0,1)\n",
    "            x_test_negative.append((x1,x2))\n",
    "\n",
    "\n",
    "    import random\n",
    "    x_train = x_train_positive + x_train_negative\n",
    "    y_train = len(x_train_positive)*[+1] + len(x_train_negative)*[-1]\n",
    "    t = list(zip(x_train, y_train))\n",
    "    random.shuffle(t)\n",
    "    x_train, y_train = zip(*t)\n",
    "    #Here our x_train and y_train Data is ready\n",
    "\n",
    "    x_test = x_test_positive + x_test_negative\n",
    "    y_test = len(x_test_positive)*[+1] + len(x_test_negative)*[-1]\n",
    "    t = list(zip(x_test, y_test))\n",
    "    random.shuffle(t)\n",
    "    x_test, y_test = zip(*t)\n",
    "    #Here our x_test and y_test Data is ready\n",
    "\n",
    "    x_train = list(x_train)\n",
    "    y_train = list(y_train)\n",
    "    x_test = list(x_test)\n",
    "    y_test = list(y_test)\n",
    "    \n",
    "    out1 = CP_Diff_Class(x_train,y_train,x_test)\n",
    "    y_pred = out1[0]\n",
    "    A1 = Accuracy(y_pred,y_test)\n",
    "    Acc_1.append(A1)\n",
    "    \n",
    "    out2 = CP_DiffBySame(x_train,y_train,x_test)\n",
    "    y_pred = out2[0]\n",
    "    A2 = Accuracy(y_pred,y_test)\n",
    "    Acc_2.append(A2)\n",
    "\n",
    "    out1 = CP_Diff_Class(x_train,y_train,x_test)\n",
    "    y_pred = out1[0]\n",
    "    p_values = out1[1]\n",
    "    other_pvalues = out1[2]\n",
    "    p_true = [] #True label of Y's Pvalue\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_test[i] == y_pred[i]:\n",
    "            p_true.append(p_values[i])   \n",
    "        else:\n",
    "            p_true.append(other_pvalues[i])\n",
    "\n",
    "    v1 = sum(p_true)/len(p_true)\n",
    "    Val_1.append(v1)\n",
    "    \n",
    "    out2 = CP_DiffBySame(x_train,y_train,x_test)\n",
    "    y_pred = out2[0]\n",
    "    p_values = out2[1]\n",
    "    other_pvalues = out1[2]\n",
    "    p_true = [] #True label of Y's Pvalue\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_test[i] == y_pred[i]:\n",
    "            p_true.append(p_values[i])\n",
    "        else:\n",
    "            p_true.append(other_pvalues[i])\n",
    "\n",
    "    v2 = sum(p_true)/len(p_true)\n",
    "    Val_2.append(v2)\n",
    "    \n",
    "    out1 = CP_Diff_Class(x_train,y_train,x_test)\n",
    "    pvalues = out1[1] \n",
    "    other_pvalues = out1[2]\n",
    "    s = []\n",
    "    for (a,b) in zip(pvalues,other_pvalues):\n",
    "        s.append(a+b)\n",
    "    sum_pvalues = sum(s)\n",
    "    length = len(pvalues)\n",
    "    E1 = sum_pvalues/length\n",
    "    Eff_1.append(E1)\n",
    "    \n",
    "    out2 = CP_DiffBySame(x_train,y_train,x_test)\n",
    "    pvalues = out2[1] \n",
    "    other_pvalues = out2[2]\n",
    "    s = []\n",
    "    for (a,b) in zip(pvalues,other_pvalues):\n",
    "        s.append(a+b)\n",
    "    sum_pvalues = sum(s)\n",
    "    length = len(pvalues)\n",
    "    E2 = sum_pvalues/length\n",
    "    Eff_2.append(E2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation Table:\n",
      "1 stands for Method 1: Nearest Neighbours to Different Class\n",
      "2 stands for Method 2: Nearest Neighbours to Diff/Same Class\n",
      "\n",
      "╒═══════════════╤═════════════╤═════════════╤═════════════╤═════════════╤═══════════════╤═══════════════╕\n",
      "│  Seed Values  │  Accuracy1  │  Accuracy2  │  Validity1  │  Validity2  │  Efficiency1  │  Efficiency2  │\n",
      "╞═══════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═══════════════╪═══════════════╡\n",
      "│       0       │   83.8462   │   84.6154   │  0.504228   │   0.54081   │   0.749912    │   0.653435    │\n",
      "├───────────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│       1       │   84.6154   │   84.6154   │  0.453318   │  0.444862   │   0.659542    │    0.52613    │\n",
      "├───────────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│       2       │   83.0769   │   85.3846   │  0.459014   │  0.464709   │   0.628303    │   0.523429    │\n",
      "├───────────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│       3       │   83.8462   │   82.3077   │  0.500411   │  0.548561   │   0.681914    │   0.634762    │\n",
      "├───────────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│       4       │   86.9231   │   86.9231   │  0.479683   │   0.50552   │   0.683382    │   0.601762    │\n",
      "├───────────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│       5       │     90      │   89.2308   │  0.497651   │  0.516089   │    0.67111    │   0.575807    │\n",
      "├───────────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│       6       │   83.8462   │   83.0769   │  0.459307   │   0.48532   │   0.605989    │   0.556078    │\n",
      "├───────────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│       7       │   87.6923   │   87.6923   │  0.488315   │   0.55185   │    0.68121    │   0.627892    │\n",
      "├───────────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│       8       │   87.6923   │   88.4615   │  0.493834   │  0.558779   │   0.652261    │   0.625719    │\n",
      "├───────────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│       9       │   83.0769   │   83.0769   │   0.45872   │   0.53394   │   0.579565    │   0.597651    │\n",
      "╘═══════════════╧═════════════╧═════════════╧═════════════╧═════════════╧═══════════════╧═══════════════╛\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "print(\"\\nObservation Table:\")\n",
    "print(\"1 stands for Method 1: Nearest Neighbours to Different Class\")\n",
    "print(\"2 stands for Method 2: Nearest Neighbours to Diff/Same Class\\n\")\n",
    "\n",
    "print(tabulate({'Seed Values': set_seeds, 'Accuracy1': Acc_1,\n",
    "                'Accuracy2': Acc_2, 'Validity1': Val_1, 'Validity2': Val_2,\n",
    "               'Efficiency1': Eff_1, 'Efficiency2': Eff_2}, headers=\"keys\", tablefmt='fancy_grid', numalign='center'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
