{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All necessary imports\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import sys\n",
    "from termcolor import colored, cprint\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CP_Diff_Class(X,Y,xt):\n",
    "    if len(X) != len(Y): #check if Samples and labels have same length\n",
    "        return \"Error:Size of Samples and Labels mismatched\"\n",
    "    \n",
    "    labels = list(set(Y)) #Finding out the distinct Labels to assign\n",
    "    \n",
    "    predicted_labels = [] #will store the predicted label\n",
    "    pvalue_pred_label = []  #stores higher pvalue scores\n",
    "    pvalue_non_pred_label = [] #stores lower pvalue scores\n",
    "    \n",
    "    for b in range(len(xt)): #Looping through all the test samples\n",
    "        test = xt[b]  #taking 1 test sample at a time\n",
    "        \n",
    "        scores_for_both_classes = [] #stores the pvalues (Here for -1 and +1)\n",
    "        return_labels = [] #consists of labels (Here -1,+1)\n",
    "        \n",
    "        for k in range(len(labels)): #Loop to iterate through labels (Here +1 and -1)\n",
    "                x =  X.copy() #Create Copy of X-train\n",
    "                y =  Y.copy() #Create Copy of Y-train\n",
    "                conformity_scores = [] # to store nearest distance to different class\n",
    "                distance_array = [] # to store all distances\n",
    "\n",
    "                x.append(test) # Create an Augmented Training Set\n",
    "                y.append(labels[k]) #Create Augmented set using a label to consider\n",
    "\n",
    "                for i in range(len(x)): #loop to find distances from different classes\n",
    "                    a1 = x[i][0] #take point 1 from tuple of (point1,point2)\n",
    "                    b1 = x[i][1] #take point 2 from tuple of (point1,point2)\n",
    "\n",
    "                    for j in range(len(x)): #looping through all the points\n",
    "                        if j!=i:  # check its not the same sample\n",
    "                            if y[i] != y[j]: #check if it has a different label\n",
    "                                a2 = x[j][0]\n",
    "                                b2 = x[j][1]\n",
    "                                t1 = (a1-a2)**2\n",
    "                                t2 = (b1-b2)**2\n",
    "                                d = np.sqrt(t1+t2) # calculations to find Euclidean Distance\n",
    "                                distance_array.append(d) #append each distance to different class in this array\n",
    "                                \n",
    "                    conformity_scores.append(min(distance_array)) #append nearest Distance to array using \"min\"\n",
    "                    distance_array.clear() #reset distance array to store next set of distances\n",
    "                \n",
    "                #After this loop we have all the nearest distances to different class in conformity_scores array\n",
    "                \n",
    "                test_sample_score = conformity_scores[len(x)-1] #take the test sample's score in a variable\n",
    "                conformity_scores.sort(reverse=True) #Sort in Descending Order to calculate rank pessimistically\n",
    "                \n",
    "                for rank in range(len(conformity_scores)): # loop to find rank\n",
    "                    if conformity_scores[rank]==test_sample_score:\n",
    "                        break\n",
    "\n",
    "                rank = len(x)-rank #Logic for Pessimistic Approach to find Rank\n",
    "                p_value = (rank)/len(x) #formula for p_value\n",
    "                \n",
    "                scores_for_both_classes.append(p_value) #stores pvalue for all the labels (Here +1 and -1)\n",
    "                return_labels.append(labels[k]) #stores corresponding labels\n",
    "\n",
    "        index_max = np.argmax(scores_for_both_classes) #getting index of higher pvalue\n",
    "        index_min = np.argmin(scores_for_both_classes) #getting index of lower pvalue\n",
    "        \n",
    "        predicted_labels.append(return_labels[index_max])  #stores predicted label\n",
    "        pvalue_pred_label.append(scores_for_both_classes[index_max]) #stores higher pvalue\n",
    "        pvalue_non_pred_label.append(scores_for_both_classes[index_min]) #stores lower pvalue\n",
    "        \n",
    "    return predicted_labels,pvalue_pred_label,pvalue_non_pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CP_DiffBySame(X,Y,xt):\n",
    "    if len(X) != len(Y): #check if Samples and labels have same length\n",
    "        return \"Error:Size of Samples and Labels mismatched\"\n",
    "        \n",
    "    labels = list(set(Y)) #Finding out the distinct Labels to assign\n",
    "    \n",
    "    predicted_labels = [] #will store the predicted label\n",
    "    pvalue_pred_label = []  #stores higher pvalue scores\n",
    "    pvalue_non_pred_label = [] #stores lower pvalue scores\n",
    "\n",
    "    for b in range(len(xt)): #Looping through all the test samples\n",
    "        test = xt[b]  #taking 1 test sample at a time\n",
    "        \n",
    "        scores_for_both_classes = [] #stores the pvalues (Here for -1 and +1)\n",
    "        return_labels = [] #consists of labels (Here -1,+1)\n",
    "        \n",
    "        for k in range(len(labels)): #Loop to iterate through labels (Here +1 and -1)\n",
    "                x =  X.copy() #Create Copy of X-train\n",
    "                y =  Y.copy() #Create Copy of Y-train\n",
    "                \n",
    "                diff_class = [] #to store nearest distances to different classes\n",
    "                same_class = [] #to store nearest distances to same classes\n",
    "                \n",
    "                conformity_scores = [] #to store diff/same class calculations\n",
    "\n",
    "                x.append(test) # Create an Augmented Training Set\n",
    "                y.append(labels[k]) #Create Augmented set using a label to consider\n",
    "\n",
    "                for i in range(len(x)): #loop to find distances from different classes\n",
    "                    a1 = x[i][0] #take point 1 from tuple of (point1,point2)\n",
    "                    b1 = x[i][1] #take point 2 from tuple of (point1,point2)\n",
    "                    distance_array1 = [] #to store all distances to different class\n",
    "                    distance_array2 = [] #to store all distances to different class\n",
    "                    for j in range(len(x)): #looping through all the points\n",
    "                        if j!=i: #check its not the same point\n",
    "                            a2 = x[j][0]\n",
    "                            b2 = x[j][1]\n",
    "                            t1 = (a1-a2)**2\n",
    "                            t2 = (b1-b2)**2\n",
    "                            d = np.sqrt(t1+t2) # formula to find Euclidean Distances   \n",
    "                            if y[i] != y[j]: #check if it is different class\n",
    "                                distance_array1.append(d) #storing Different Classes Distances\n",
    "                            else: #else it is same class\n",
    "                                distance_array2.append(d) #storing Same Classes Distances\n",
    "\n",
    "                    diff_class.append(min(distance_array1)) #stores Nearest Distance to Different Class\n",
    "                    same_class.append(min(distance_array2)) #stores Nearest Distance to Same Class\n",
    "\n",
    "                for r in range(len(same_class)):  #remove zero values\n",
    "                    if same_class[r] == 0:\n",
    "                        same_class[r] = 0.00001\n",
    "                        \n",
    "                #Logic to calculate find Diff/Same Scores\n",
    "                conformity_scores = [ p/q for p,q in zip(diff_class,same_class) ]   \n",
    "\n",
    "                test_sample_score = conformity_scores[len(x)-1]\n",
    "                conformity_scores.sort(reverse=True) #Sort in Descending Order to Calculate rank Pessimistically\n",
    "                \n",
    "                for rank in range(len(x)): #Loop to find the rank\n",
    "                    if conformity_scores[rank]==test_sample_score:\n",
    "                        break\n",
    "\n",
    "                rank = len(x)-rank #Logic for Pessimistic Approach to find Rank\n",
    "                p_value = (rank)/len(x) #formula for p_value\n",
    "                \n",
    "                scores_for_both_classes.append(p_value) #stores pvalue for all the labels (Here +1 and -1)\n",
    "                return_labels.append(labels[k]) #stores corresponding labels\n",
    "\n",
    "        index_max = np.argmax(scores_for_both_classes) #getting index of higher pvalue\n",
    "        index_min = np.argmin(scores_for_both_classes) #getting index of lower pvalue\n",
    "        \n",
    "        predicted_labels.append(return_labels[index_max])  #stores predicted label\n",
    "        pvalue_pred_label.append(scores_for_both_classes[index_max]) #stores higher pvalue\n",
    "        pvalue_non_pred_label.append(scores_for_both_classes[index_min]) #stores lower pvalue\n",
    "\n",
    "    return predicted_labels,pvalue_pred_label,pvalue_non_pred_label\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(y_pred,y_test):\n",
    "    count = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if(y_pred[i]==y_test[i]):\n",
    "            count+=1\n",
    "    return (count/len(y_pred))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Validity(output):\n",
    "    y_pred,p_values,other_pvalues = output[0],output[1],output[2]\n",
    "    p_true = [] #True label of Y's Pvalue\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_test[i] == y_pred[i]:\n",
    "            p_true.append(p_values[i])   \n",
    "        else:\n",
    "            p_true.append(other_pvalues[i])\n",
    "    return sum(p_true)/len(p_true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficiency Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Efficiency(output):\n",
    "    pvalues, other_pvalues = output[1], output[2]\n",
    "    s = [x + y for x, y in zip(pvalues, other_pvalues)]\n",
    "    return sum(s)/len(pvalues)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program to Create Artificial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "x_train_positive,x_train_negative,x_test_positive,x_test_negative=[],[],[],[]\n",
    "\n",
    "#Creating positive training data around point (2,3) with noise level 1\n",
    "x_m, y_m, s = 2,3,1\n",
    "for i in range(60):\n",
    "        x1 = x_m + s*np.random.normal(0,1)\n",
    "        x2 = y_m + s*np.random.normal(0,1)\n",
    "        x_train_positive.append((x1,x2))\n",
    "\n",
    "#Creating negative training data around point (0,0) with noise level 2\n",
    "x_m, y_m, s = 0,0,2\n",
    "for i in range(70):\n",
    "        x1 = x_m + s*np.random.normal(0,1)\n",
    "        x2 = y_m + s*np.random.normal(0,1)\n",
    "        x_train_negative.append((x1,x2))\n",
    "    \n",
    "#Creating positive testing data around point (2,3) with noise level 1\n",
    "x_m, y_m, s = 2,3,1\n",
    "for i in range(70):\n",
    "        x1 = x_m + s*np.random.normal(0,1)\n",
    "        x2 = y_m + s*np.random.normal(0,1)\n",
    "        x_test_positive.append((x1,x2))\n",
    "\n",
    "#Creating negative testing data around point (0,0) with noise level 2\n",
    "x_m, y_m, s = 0,0,2\n",
    "for i in range(60):\n",
    "        x1 = x_m + s*np.random.normal(0,1)\n",
    "        x2 = y_m + s*np.random.normal(0,1)\n",
    "        x_test_negative.append((x1,x2))\n",
    "        \n",
    "x_train = x_train_positive + x_train_negative\n",
    "y_train = len(x_train_positive)*[+1] + len(x_train_negative)*[-1]\n",
    "t = list(zip(x_train, y_train))\n",
    "random.shuffle(t)\n",
    "x_train, y_train = zip(*t)\n",
    "#Here our x_train and y_train data is ready\n",
    "\n",
    "x_test = x_test_positive + x_test_negative\n",
    "y_test = len(x_test_positive)*[+1] + len(x_test_negative)*[-1]\n",
    "t = list(zip(x_test, y_test))\n",
    "random.shuffle(t)\n",
    "x_test, y_test = zip(*t)\n",
    "#Here our x_test and y_test Data is ready\n",
    "\n",
    "x_train = list(x_train)\n",
    "y_train = list(y_train)\n",
    "x_test = list(x_test)\n",
    "y_test = list(y_test)\n",
    "#convert them to lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using Diff/Same Class is:  95.38461538461539\n",
      "Accuracy using Different Class is:  95.38461538461539\n",
      "\n",
      "Validity for Different Class method is:  0.5588960657662947\n",
      "Validity for Different/Same Class method is:  0.5896065766294778\n",
      "\n",
      "Efficiency for Different Class method is:  0.7475631238990017\n",
      "Efficiency for Diff/Same Class method is:  0.6352906635349385\n"
     ]
    }
   ],
   "source": [
    "# Testing our Results with the artificial data\n",
    "out1 = CP_Diff_Class(x_train,y_train,x_test)\n",
    "out2 = CP_DiffBySame(x_train,y_train,x_test)\n",
    "\n",
    "print(\"Accuracy using Diff/Same Class is: \",Accuracy(out1[0],y_test))\n",
    "print(\"Accuracy using Different Class is: \",Accuracy(out2[0],y_test))\n",
    "\n",
    "\n",
    "print(\"\\nValidity for Different Class method is: \",Validity(out1))\n",
    "print(\"Validity for Different/Same Class method is: \",Validity(out2))\n",
    "\n",
    "print(\"\\nEfficiency for Different Class method is: \",Efficiency(out1))\n",
    "print(\"Efficiency for Diff/Same Class method is: \",Efficiency(out2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with different seed values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds,Acc_1,Acc_2,Val_1,Val_2,Eff_1,Eff_2,Acc_1_int,Acc_2_int,Val_1_int,Val_2_int,Eff_1_int,Eff_2_int = ([] for i in range(13))\n",
    "\n",
    "for seed_value in range(1,10):\n",
    "    np.random.seed(seed_value)\n",
    "    seeds.append(seed_value)\n",
    "    x_train_positive,x_train_negative,x_test_positive,x_test_negative=[],[],[],[]\n",
    "\n",
    "    #Creating positive training data around point (2,3) with noise level 1\n",
    "    x_m, y_m, s = 2,3,1\n",
    "    for i in range(60):\n",
    "            x1 = x_m + s*np.random.normal(0,1)\n",
    "            x2 = y_m + s*np.random.normal(0,1)\n",
    "            x_train_positive.append((x1,x2))\n",
    "\n",
    "    #Creating negative training data around point (0,0) with noise level 2       \n",
    "    x_m, y_m, s = 0,0,2\n",
    "    for i in range(70):\n",
    "            x1 = x_m + s*np.random.normal(0,1)\n",
    "            x2 = y_m + s*np.random.normal(0,1)\n",
    "            x_train_negative.append((x1,x2))\n",
    "\n",
    "    #Creating positive testing data around point (2,3) with noise level 1\n",
    "    x_m, y_m, s = 2,3,1\n",
    "    for i in range(70):\n",
    "            x1 = x_m + s*np.random.normal(0,1)\n",
    "            x2 = y_m + s*np.random.normal(0,1)\n",
    "            x_test_positive.append((x1,x2))\n",
    "\n",
    "    #Creating negative testing data around point (0,0) with noise level 2\n",
    "    x_m, y_m, s = 0,0,2\n",
    "    for i in range(60):\n",
    "            x1 = x_m + s*np.random.normal(0,1)\n",
    "            x2 = y_m + s*np.random.normal(0,1)\n",
    "            x_test_negative.append((x1,x2))\n",
    "\n",
    "    x_train = x_train_positive + x_train_negative\n",
    "    y_train = len(x_train_positive)*[+1] + len(x_train_negative)*[-1]\n",
    "    t = list(zip(x_train, y_train))\n",
    "    random.shuffle(t)\n",
    "    x_train, y_train = zip(*t)\n",
    "\n",
    "    x_test = x_test_positive + x_test_negative\n",
    "    y_test = len(x_test_positive)*[+1] + len(x_test_negative)*[-1]\n",
    "    t = list(zip(x_test, y_test))\n",
    "    random.shuffle(t)\n",
    "    x_test, y_test = zip(*t)\n",
    "    \n",
    "    x_train, y_train, x_test, y_test = list(x_train), list(y_train), list(x_test), list(y_test)\n",
    "\n",
    "    out1 = CP_Diff_Class(x_train,y_train,x_test)\n",
    "    out2 = CP_DiffBySame(x_train,y_train,x_test)\n",
    "    \n",
    "    A1 = Accuracy(out1[0],y_test)\n",
    "    Acc_1_int.append(A1)\n",
    "    if(A1>=80): A1 = colored(A1, 'green', attrs=['reverse', 'blink'])\n",
    "    elif((A1>=60) & (A1<80)): A1 = colored(A1, 'yellow', attrs=['reverse', 'blink'])\n",
    "    else: A1 = colored(A1, 'red', attrs=['reverse', 'blink'])\n",
    "    Acc_1.append(A1)\n",
    "\n",
    "    A2 = Accuracy(out2[0],y_test)\n",
    "    Acc_2_int.append(A2)\n",
    "    if(A2>=80): A2 = colored(A2, 'green', attrs=['reverse', 'blink'])\n",
    "    elif((A2>=60) & (A2<80)): A2 = colored(A2, 'yellow', attrs=['reverse', 'blink'])\n",
    "    else: A2 = colored(A2, 'red', attrs=['reverse', 'blink'])\n",
    "    Acc_2.append(A2)\n",
    "\n",
    "    v1 = Validity(out1)\n",
    "    Val_1_int.append(v1)\n",
    "    if(v1>=0.45): v1 = colored(v1, 'green', attrs=['reverse', 'blink'])\n",
    "    else: v1 = colored(v1, 'red', attrs=['reverse', 'blink'])\n",
    "    Val_1.append(v1)\n",
    "\n",
    "    v2 = Validity(out2)\n",
    "    Val_2_int.append(v2)\n",
    "    if(v2>=0.45): v2 = colored(v2, 'green', attrs=['reverse', 'blink'])\n",
    "    else: v2 = colored(v2, 'red', attrs=['reverse', 'blink'])\n",
    "    Val_2.append(v2)\n",
    "\n",
    "    E1 = Efficiency(out1)\n",
    "    Eff_1_int.append(E1)\n",
    "    if(E1>=0.80): E1 = colored(E1, 'red', attrs=['reverse', 'blink'])\n",
    "    elif((E1<0.80) & (E1>=0.70)): E1 = colored(E1, 'yellow', attrs=['reverse', 'blink'])\n",
    "    else: E1 = colored(E1, 'green', attrs=['reverse', 'blink'])\n",
    "    Eff_1.append(E1)\n",
    "\n",
    "    E2 = Efficiency(out2)\n",
    "    Eff_2_int.append(E2)\n",
    "    if(E2>=0.80): E2 = colored(E2, 'red', attrs=['reverse', 'blink'])\n",
    "    elif((E2<0.80) & (E2>=0.70)): E2 = colored(E2, 'yellow', attrs=['reverse', 'blink'])\n",
    "    else: E2 = colored(E2, 'green', attrs=['reverse', 'blink'])\n",
    "    Eff_2.append(E2)    \n",
    "\n",
    "seeds.append(\"Average\")\n",
    "Acc_1.append(sum(Acc_1_int)/len(Acc_1_int))\n",
    "Acc_2.append(sum(Acc_2_int)/len(Acc_2_int))\n",
    "Val_1.append(sum(Val_1_int)/len(Val_1_int))\n",
    "Val_2.append(sum(Val_2_int)/len(Val_2_int))\n",
    "Eff_1.append(sum(Eff_1_int)/len(Eff_1_int))\n",
    "Eff_2.append(sum(Eff_2_int)/len(Eff_2_int))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation Table:\n",
      "1 stands for Method 1: Nearest Neighbours to Different Class\n",
      "2 stands for Method 2: Nearest Neighbours to Diff/Same Class\n",
      "\n",
      "╒═══════════════╤═════════════╤═════════════╤═════════════╤═════════════╤═══════════════╤═══════════════╕\n",
      "│ Seed Values   │  Accuracy1  │  Accuracy2  │  Validity1  │  Validity2  │  Efficiency1  │  Efficiency2  │\n",
      "╞═══════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═══════════════╪═══════════════╡\n",
      "│ 1             │   \u001b[5m\u001b[7m\u001b[32m86.1538\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m86.9231\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.493776\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.490781\u001b[0m   │   \u001b[5m\u001b[7m\u001b[33m0.726013\u001b[0m    │   \u001b[5m\u001b[7m\u001b[32m0.585907\u001b[0m    │\n",
      "├───────────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│ 2             │   \u001b[5m\u001b[7m\u001b[32m95.3846\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m95.3846\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.558896\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.589607\u001b[0m   │   \u001b[5m\u001b[7m\u001b[33m0.747563\u001b[0m    │   \u001b[5m\u001b[7m\u001b[32m0.635291\u001b[0m    │\n",
      "├───────────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│ 3             │   \u001b[5m\u001b[7m\u001b[32m83.0769\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m83.0769\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.469701\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m0.47017\u001b[0m   │    \u001b[5m\u001b[7m\u001b[32m0.66512\u001b[0m    │    \u001b[5m\u001b[7m\u001b[32m0.57751\u001b[0m    │\n",
      "├───────────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│ 4             │   \u001b[5m\u001b[7m\u001b[32m90.7692\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m90.7692\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.518203\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.514797\u001b[0m   │   \u001b[5m\u001b[7m\u001b[33m0.718673\u001b[0m    │   \u001b[5m\u001b[7m\u001b[32m0.591779\u001b[0m    │\n",
      "├───────────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│ 5             │   \u001b[5m\u001b[7m\u001b[32m89.2308\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m89.2308\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.487023\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.513212\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m0.657428\u001b[0m    │   \u001b[5m\u001b[7m\u001b[32m0.578978\u001b[0m    │\n",
      "├───────────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│ 6             │   \u001b[5m\u001b[7m\u001b[32m83.8462\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m83.8462\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.511861\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.520728\u001b[0m   │   \u001b[5m\u001b[7m\u001b[33m0.727129\u001b[0m    │    \u001b[5m\u001b[7m\u001b[32m0.6202\u001b[0m     │\n",
      "├───────────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│ 7             │   \u001b[5m\u001b[7m\u001b[32m90.7692\u001b[0m   │     \u001b[5m\u001b[7m\u001b[32m90\u001b[0m      │  \u001b[5m\u001b[7m\u001b[32m0.499883\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.514269\u001b[0m   │    \u001b[5m\u001b[7m\u001b[32m0.68303\u001b[0m    │   \u001b[5m\u001b[7m\u001b[32m0.592132\u001b[0m    │\n",
      "├───────────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│ 8             │   \u001b[5m\u001b[7m\u001b[32m83.0769\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m82.3077\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.461715\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.463006\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m0.667998\u001b[0m    │   \u001b[5m\u001b[7m\u001b[32m0.573693\u001b[0m    │\n",
      "├───────────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│ 9             │   \u001b[5m\u001b[7m\u001b[32m80.7692\u001b[0m   │     \u001b[5m\u001b[7m\u001b[32m80\u001b[0m      │  \u001b[5m\u001b[7m\u001b[32m0.474163\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.510217\u001b[0m   │   \u001b[5m\u001b[7m\u001b[33m0.730299\u001b[0m    │   \u001b[5m\u001b[7m\u001b[32m0.658133\u001b[0m    │\n",
      "├───────────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│ Average       │   87.0085   │   86.8376   │  0.497247   │  0.509643   │   0.702584    │   0.601514    │\n",
      "╘═══════════════╧═════════════╧═════════════╧═════════════╧═════════════╧═══════════════╧═══════════════╛\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nObservation Table:\")\n",
    "print(\"1 stands for Method 1: Nearest Neighbours to Different Class\")\n",
    "print(\"2 stands for Method 2: Nearest Neighbours to Diff/Same Class\\n\")\n",
    "\n",
    "print(tabulate({'Seed Values': seeds, 'Accuracy1': Acc_1,\n",
    "                'Accuracy2': Acc_2, 'Validity1': Val_1, 'Validity2': Val_2,\n",
    "               'Efficiency1': Eff_1, 'Efficiency2': Eff_2}, headers=\"keys\", tablefmt='fancy_grid', numalign='center'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with different levels of noise in negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Noise,Acc_1,Acc_2,Val_1,Val_2,Eff_1,Eff_2= ([] for i in range(7))\n",
    "\n",
    "for noise_level in range(1,10):\n",
    "    np.random.seed(3)\n",
    "    Noise.append(noise_level)\n",
    "    x_train_positive,x_train_negative,x_test_positive,x_test_negative=[],[],[],[]\n",
    "\n",
    "    #Creating positive training data around point (2,3) with noise level 1\n",
    "    x_m, y_m, s = 2,3,1\n",
    "    for i in range(60):\n",
    "            x1 = x_m + s*np.random.normal(0,1)\n",
    "            x2 = y_m + s*np.random.normal(0,1)\n",
    "            x_train_positive.append((x1,x2))\n",
    "\n",
    "    #Creating negative training data around point (0,0) with noise level 2\n",
    "    x_m, y_m, s = 0,0,2\n",
    "    for i in range(70):\n",
    "            x1 = x_m + s*np.random.normal(0,1)\n",
    "            x2 = y_m + s*np.random.normal(0,1)\n",
    "            x_train_negative.append((x1,x2))\n",
    "\n",
    "    #Creating positive testing data around point (2,3) with noise level 1\n",
    "    x_m, y_m, s = 2,3,1\n",
    "    for i in range(70):\n",
    "            x1 = x_m + s*np.random.normal(0,1)\n",
    "            x2 = y_m + s*np.random.normal(0,1)\n",
    "            x_test_positive.append((x1,x2))\n",
    "\n",
    "    #Creating negative testing data around point (0,0) with noise \"noise_level\" (Transfer)\n",
    "    x_m, y_m, s = 0,0,noise_level\n",
    "    for i in range(60):\n",
    "            x1 = x_m + s*np.random.normal(0,1)\n",
    "            x2 = y_m + s*np.random.normal(0,1)\n",
    "            x_test_negative.append((x1,x2))\n",
    "\n",
    "    x_train = x_train_positive + x_train_negative\n",
    "    y_train = len(x_train_positive)*[+1] + len(x_train_negative)*[-1]\n",
    "    t = list(zip(x_train, y_train))\n",
    "    random.shuffle(t)\n",
    "    x_train, y_train = zip(*t)\n",
    "\n",
    "    x_test = x_test_positive + x_test_negative\n",
    "    y_test = len(x_test_positive)*[+1] + len(x_test_negative)*[-1]\n",
    "    t = list(zip(x_test, y_test))\n",
    "    random.shuffle(t)\n",
    "    x_test, y_test = zip(*t)\n",
    "\n",
    "    x_train, y_train, x_test, y_test = list(x_train), list(y_train), list(x_test), list(y_test)\n",
    "\n",
    "    out1 = CP_Diff_Class(x_train,y_train,x_test)\n",
    "    out2 = CP_DiffBySame(x_train,y_train,x_test)\n",
    "\n",
    "    A1 = Accuracy(out1[0],y_test)\n",
    "    if(A1>=80): A1 = colored(A1, 'green', attrs=['reverse', 'blink'])\n",
    "    elif((A1>=60) & (A1<80)): A1 = colored(A1, 'yellow', attrs=['reverse', 'blink'])\n",
    "    else: A1 = colored(A1, 'red', attrs=['reverse', 'blink'])\n",
    "    Acc_1.append(A1)\n",
    "\n",
    "    A2 = Accuracy(out2[0],y_test)\n",
    "    if(A2>=80): A2 = colored(A2, 'green', attrs=['reverse', 'blink'])\n",
    "    elif((A2>=60) & (A2<80)): A2 = colored(A2, 'yellow', attrs=['reverse', 'blink'])\n",
    "    else: A2 = colored(A2, 'red', attrs=['reverse', 'blink'])\n",
    "    Acc_2.append(A2)\n",
    "\n",
    "    v1 = Validity(out1)\n",
    "    if(v1>=0.45): v1 = colored(v1, 'green', attrs=['reverse', 'blink'])\n",
    "    elif((v1<0.45)&(v1>=0.40)): v1 = colored(v1, 'yellow', attrs=['reverse', 'blink'])\n",
    "    else: v1 = colored(v1, 'red', attrs=['reverse', 'blink'])\n",
    "    Val_1.append(v1)\n",
    "\n",
    "    v2 = Validity(out2)\n",
    "    if(v2>=0.45): v2 = colored(v2, 'green', attrs=['reverse', 'blink'])\n",
    "    elif((v2<0.45)&(v2>=0.40)): v2 = colored(v2, 'yellow', attrs=['reverse', 'blink'])\n",
    "    else: v2 = colored(v2, 'red', attrs=['reverse', 'blink'])\n",
    "    Val_2.append(v2)\n",
    "\n",
    "\n",
    "    E1 = Efficiency(out1)\n",
    "    if(E1>=1): E1 = colored(E1, 'red', attrs=['reverse', 'blink'])\n",
    "    elif((E1<1) & (E1>=0.80)): E1 = colored(E1, 'yellow', attrs=['reverse', 'blink'])\n",
    "    else: E1 = colored(E1, 'green', attrs=['reverse', 'blink'])\n",
    "    Eff_1.append(E1)\n",
    "\n",
    "    E2 = Efficiency(out2)\n",
    "    if(E2>=1): E2 = colored(E2, 'red', attrs=['reverse', 'blink'])\n",
    "    elif((E2<1) & (E2>=0.80)): E2 = colored(E2, 'yellow', attrs=['reverse', 'blink'])\n",
    "    else: E2 = colored(E2, 'green', attrs=['reverse', 'blink'])\n",
    "    Eff_2.append(E2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation Table after Introducing Noise to X_test(-1 Class):\n",
      "1 stands for Method 1: Nearest Neighbours to Different Class\n",
      "2 stands for Method 2: Nearest Neighbours to Diff/Same Class\n",
      "\n",
      "╒═════════╤═════════════╤═════════════╤═════════════╤═════════════╤═══════════════╤═══════════════╕\n",
      "│  Noise  │  Accuracy1  │  Accuracy2  │  Validity1  │  Validity2  │  Efficiency1  │  Efficiency2  │\n",
      "╞═════════╪═════════════╪═════════════╪═════════════╪═════════════╪═══════════════╪═══════════════╡\n",
      "│    1    │   \u001b[5m\u001b[7m\u001b[32m86.9231\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m87.6923\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.466412\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.512272\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m0.608045\u001b[0m    │   \u001b[5m\u001b[7m\u001b[32m0.584733\u001b[0m    │\n",
      "├─────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│    2    │   \u001b[5m\u001b[7m\u001b[32m83.0769\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m83.0769\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.469701\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m0.47017\u001b[0m   │    \u001b[5m\u001b[7m\u001b[32m0.66512\u001b[0m    │    \u001b[5m\u001b[7m\u001b[32m0.57751\u001b[0m    │\n",
      "├─────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│    3    │   \u001b[5m\u001b[7m\u001b[32m84.6154\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m84.6154\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.501996\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.472578\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m0.751262\u001b[0m    │   \u001b[5m\u001b[7m\u001b[32m0.573576\u001b[0m    │\n",
      "├─────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│    4    │   \u001b[5m\u001b[7m\u001b[32m83.0769\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m83.0769\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.539401\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.450558\u001b[0m   │   \u001b[5m\u001b[7m\u001b[33m0.857898\u001b[0m    │    \u001b[5m\u001b[7m\u001b[32m0.55461\u001b[0m    │\n",
      "├─────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│    5    │   \u001b[5m\u001b[7m\u001b[32m83.0769\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m84.6154\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.572284\u001b[0m   │  \u001b[5m\u001b[7m\u001b[33m0.423429\u001b[0m   │   \u001b[5m\u001b[7m\u001b[33m0.947035\u001b[0m    │   \u001b[5m\u001b[7m\u001b[32m0.514621\u001b[0m    │\n",
      "├─────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│    6    │   \u001b[5m\u001b[7m\u001b[33m75.3846\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m83.8462\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.587317\u001b[0m   │  \u001b[5m\u001b[7m\u001b[31m0.394245\u001b[0m   │    \u001b[5m\u001b[7m\u001b[31m1.01368\u001b[0m    │   \u001b[5m\u001b[7m\u001b[32m0.499354\u001b[0m    │\n",
      "├─────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│    7    │   \u001b[5m\u001b[7m\u001b[33m69.2308\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m83.8462\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.604815\u001b[0m   │  \u001b[5m\u001b[7m\u001b[31m0.377745\u001b[0m   │    \u001b[5m\u001b[7m\u001b[31m1.06506\u001b[0m    │   \u001b[5m\u001b[7m\u001b[32m0.477158\u001b[0m    │\n",
      "├─────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│    8    │   \u001b[5m\u001b[7m\u001b[33m64.6154\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m83.8462\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.615267\u001b[0m   │  \u001b[5m\u001b[7m\u001b[31m0.363417\u001b[0m   │    \u001b[5m\u001b[7m\u001b[31m1.09659\u001b[0m    │   \u001b[5m\u001b[7m\u001b[32m0.465531\u001b[0m    │\n",
      "├─────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│    9    │   \u001b[5m\u001b[7m\u001b[33m60.7692\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m83.8462\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.620258\u001b[0m   │  \u001b[5m\u001b[7m\u001b[31m0.354433\u001b[0m   │    \u001b[5m\u001b[7m\u001b[31m1.11298\u001b[0m    │   \u001b[5m\u001b[7m\u001b[32m0.457487\u001b[0m    │\n",
      "╘═════════╧═════════════╧═════════════╧═════════════╧═════════════╧═══════════════╧═══════════════╛\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nObservation Table after Introducing Noise to X_test(-1 Class):\")\n",
    "print(\"1 stands for Method 1: Nearest Neighbours to Different Class\")\n",
    "print(\"2 stands for Method 2: Nearest Neighbours to Diff/Same Class\\n\")\n",
    "\n",
    "\n",
    "print(tabulate({'Noise': Noise, 'Accuracy1': Acc_1,\n",
    "                'Accuracy2': Acc_2, 'Validity1': Val_1, 'Validity2': Val_2,\n",
    "               'Efficiency1': Eff_1, 'Efficiency2': Eff_2}, headers=\"keys\", tablefmt='fancy_grid', numalign='center'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphical Representation of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(3)\n",
    "x_train_positive=[]\n",
    "x_m = 2\n",
    "y_m = 3\n",
    "s = 1 \n",
    "for i in range(800):\n",
    "        x1 = x_m + s*np.random.normal(0,1)\n",
    "        x2 = y_m + s*np.random.normal(0,1)\n",
    "        x_train_positive.append((x1,x2))\n",
    "\n",
    "x_train_negative=[]\n",
    "x_m = 0\n",
    "y_m = 0\n",
    "s = 2\n",
    "for i in range(800):\n",
    "        x1 = x_m + s*np.random.normal(0,1)\n",
    "        x2 = y_m + s*np.random.normal(0,1)\n",
    "        x_train_negative.append((x1,x2))\n",
    "\n",
    "\n",
    "x_train = x_train_positive + x_train_negative\n",
    "y_train = len(x_train_positive)*[+1] + len(x_train_negative)*[-1]\n",
    "x1 = [x_train_positive[i][0] for i in range(len(x_train_positive))]\n",
    "x2 = [x_train_positive[i][1] for i in range(len(x_train_positive))]\n",
    "plt.scatter(x1,x2,c=\"red\")\n",
    "plt.text(2,3,\"Class +1\")\n",
    "p1 = [x_train_negative[i][0] for i in range(len(x_train_negative))]\n",
    "p2 = [x_train_negative[i][1] for i in range(len(x_train_negative))]\n",
    "plt.scatter(p1,p2,c=\"green\")\n",
    "plt.text(0,0,\"Class -1\")\n",
    "plt.title(\"Points for classes -1 and +1\")\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96eb50e1d44aed467dc8f759cb08c32fbfa9babcf79c554e2d0e5feb04653a10"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
