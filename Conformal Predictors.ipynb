{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CP_Diff_Class(X,Y,xt):\n",
    "    if len(X) == len(Y): #check if Samples and labels have same length\n",
    "        labels = list(set(Y)) #Finding out the distinct Labels to assign\n",
    "        \n",
    "        predicted_labels = [] #will store the predicted label\n",
    "        pred_label_conformity_score = []  #stores higher pvalue scores\n",
    "        other_label_conformity_score = [] #stores lower pvalue scores\n",
    "        \n",
    "        for b in range(len(xt)): #Looping through all the test samples\n",
    "            test = xt[b]  #taking 1 test sample at a time\n",
    "            \n",
    "            scores_for_both_classes = [] #stores the pvalues (Here for -1 and +1)\n",
    "            return_labels = [] #consists of labels (Here -1,+1)\n",
    "            \n",
    "            for k in range(len(labels)): #Loop to iterate through labels (Here +1 and -1)\n",
    "                    x =  X.copy() #Create Copy of X-train\n",
    "                    y =  Y.copy() #Create Copy of Y-train\n",
    "                    conformity_scores = [] # to store nearest distance to different class\n",
    "                    distance_array = [] # to store all distances\n",
    "\n",
    "                    x.append(test) # Create an Augmented Training Set\n",
    "                    y.append(labels[k]) #Create Augmented set using a label to consider\n",
    "\n",
    "                    for i in range(len(x)): #loop to find distances from different classes\n",
    "                        a1 = x[i][0] #take point 1 from tuple of (point1,point2)\n",
    "                        b1 = x[i][1] #take point 2 from tuple of (point1,point2)\n",
    "\n",
    "                        for j in range(len(x)): #looping through all the points\n",
    "                            if j!=i:  # check its not the same sample\n",
    "                                if y[i] != y[j]: #check if it has a different label\n",
    "                                    a2 = x[j][0]\n",
    "                                    b2 = x[j][1]\n",
    "                                    t1 = (a1-a2)**2\n",
    "                                    t2 = (b1-b2)**2\n",
    "                                    d = np.sqrt(t1+t2) # calculations to find Euclidean Distance\n",
    "                                    distance_array.append(d) #append each distance to different class in this array\n",
    "                                    \n",
    "                        conformity_scores.append(min(distance_array)) #append nearest Distance to array using \"min\"\n",
    "                        distance_array.clear() #reset distance array to store next set of distances\n",
    "                    \n",
    "                    #After this loop we have all the nearest distances to different class in conformity_scores array\n",
    "                    \n",
    "                    test_sample_score = conformity_scores[len(x)-1] #take the test sample's score in a variable\n",
    "                    conformity_scores.sort(reverse=True) #Sort in Descending Order to calculate rank pessimistically\n",
    "                    \n",
    "                    for rank in range(len(conformity_scores)): # loop to find rank\n",
    "                        if conformity_scores[rank]==test_sample_score:\n",
    "                            break\n",
    "\n",
    "                    rank = len(x)-rank #Logic for Pessimistic Approach to find Rank\n",
    "                    p_value = (rank)/len(x) #formula for p_value\n",
    "                    \n",
    "                    scores_for_both_classes.append(p_value) #stores pvalue for all the labels (Here +1 and -1)\n",
    "                    return_labels.append(labels[k]) #stores corresponding labels\n",
    "\n",
    "            index_max = np.argmax(scores_for_both_classes) #getting index of higher pvalue\n",
    "            index_min = np.argmin(scores_for_both_classes) #getting index of lower pvalue\n",
    "            \n",
    "            predicted_labels.append(return_labels[index_max])  #stores predicted label\n",
    "            pred_label_conformity_score.append(scores_for_both_classes[index_max]) #stores higher pvalue\n",
    "            other_label_conformity_score.append(scores_for_both_classes[index_min]) #stores lower pvalue\n",
    "            \n",
    "        return predicted_labels,pred_label_conformity_score,other_label_conformity_score\n",
    "    else:\n",
    "        return \"Error:Size of Samples and Labels mismatched\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CP_DiffBySame(X,Y,xt):\n",
    "    if len(X) == len(Y): #check if Samples and labels have same length\n",
    "        labels = list(set(Y)) #Finding out the distinct Labels to assign\n",
    "        \n",
    "        predicted_labels = [] #will store the predicted label\n",
    "        pred_label_conformity_score = []  #stores higher pvalue scores\n",
    "        other_label_conformity_score = [] #stores lower pvalue scores\n",
    "\n",
    "        for b in range(len(xt)): #Looping through all the test samples\n",
    "            test = xt[b]  #taking 1 test sample at a time\n",
    "            \n",
    "            scores_for_both_classes = [] #stores the pvalues (Here for -1 and +1)\n",
    "            return_labels = [] #consists of labels (Here -1,+1)\n",
    "            \n",
    "            for k in range(len(labels)): #Loop to iterate through labels (Here +1 and -1)\n",
    "                    x =  X.copy() #Create Copy of X-train\n",
    "                    y =  Y.copy() #Create Copy of Y-train\n",
    "                    \n",
    "                    diff_class = [] #to store nearest distances to different classes\n",
    "                    same_class = [] #to store nearest distances to same classes\n",
    "                    \n",
    "                    conformity_scores = [] #to store diff/same class calculations\n",
    "\n",
    "                    x.append(test) # Create an Augmented Training Set\n",
    "                    y.append(labels[k]) #Create Augmented set using a label to consider\n",
    "\n",
    "                    for i in range(len(x)): #loop to find distances from different classes\n",
    "                        a1 = x[i][0] #take point 1 from tuple of (point1,point2)\n",
    "                        b1 = x[i][1] #take point 2 from tuple of (point1,point2)\n",
    "                        distance_array1 = [] #to store all distances to different class\n",
    "                        distance_array2 = [] #to store all distances to different class\n",
    "                        for j in range(len(x)): #looping through all the points\n",
    "                            if j!=i: #check its not the same point\n",
    "                                a2 = x[j][0]\n",
    "                                b2 = x[j][1]\n",
    "                                t1 = (a1-a2)**2\n",
    "                                t2 = (b1-b2)**2\n",
    "                                d = np.sqrt(t1+t2) # formula to find Euclidean Distances   \n",
    "                                if y[i] != y[j]: #check if it is different class\n",
    "                                    distance_array1.append(d) #storing Different Classes Distances\n",
    "                                else: #else it is same class\n",
    "                                    distance_array2.append(d) #storing Same Classes Distances\n",
    "\n",
    "                        diff_class.append(min(distance_array1)) #stores Nearest Distance to Different Class\n",
    "                        same_class.append(min(distance_array2)) #stores Nearest Distance to Same Class\n",
    "\n",
    "                    for r in range(len(same_class)):  #remove zero values\n",
    "                        if same_class[r] == 0:\n",
    "                            same_class[r] = 0.00001\n",
    "                            \n",
    "                    #Logic to calculate find Diff/Same Scores\n",
    "                    conformity_scores = [ p/q for p,q in zip(diff_class,same_class) ]   \n",
    "\n",
    "                    test_sample_score = conformity_scores[len(x)-1]\n",
    "                    conformity_scores.sort(reverse=True) #Sort in Descending Order to Calculate rank Pessimistically\n",
    "                    \n",
    "                    for rank in range(len(x)): #Loop to find the rank\n",
    "                        if conformity_scores[rank]==test_sample_score:\n",
    "                            break\n",
    "\n",
    "                    rank = len(x)-rank #Logic for Pessimistic Approach to find Rank\n",
    "                    p_value = (rank)/len(x) #formula for p_value\n",
    "                    \n",
    "                    scores_for_both_classes.append(p_value) #stores pvalue for all the labels (Here +1 and -1)\n",
    "                    return_labels.append(labels[k]) #stores corresponding labels\n",
    "\n",
    "            index_max = np.argmax(scores_for_both_classes) #getting index of higher pvalue\n",
    "            index_min = np.argmin(scores_for_both_classes) #getting index of lower pvalue\n",
    "            \n",
    "            predicted_labels.append(return_labels[index_max])  #stores predicted label\n",
    "            pred_label_conformity_score.append(scores_for_both_classes[index_max]) #stores higher pvalue\n",
    "            other_label_conformity_score.append(scores_for_both_classes[index_min]) #stores lower pvalue\n",
    " \n",
    "        return predicted_labels,pred_label_conformity_score,other_label_conformity_score\n",
    "    else:\n",
    "        return \"Error:Size of Samples and Labels mismatched\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program to Create Artificial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, random\n",
    "random.seed(3)\n",
    "x_train_positive,x_train_negative,x_test_positive,x_test_negative=[],[],[],[]\n",
    "\n",
    "x_m, y_m, s = 2,3,1\n",
    "for i in range(60):\n",
    "        x1 = x_m + s*np.random.normal(0,1)\n",
    "        x2 = y_m + s*np.random.normal(0,1)\n",
    "        x_train_positive.append((x1,x2))\n",
    "\n",
    "x_m, y_m, s = 0,0,2\n",
    "for i in range(70):\n",
    "        x1 = x_m + s*np.random.normal(0,1)\n",
    "        x2 = y_m + s*np.random.normal(0,1)\n",
    "        x_train_negative.append((x1,x2))\n",
    "    \n",
    "x_m, y_m, s = 2,3,1\n",
    "for i in range(70):\n",
    "        x1 = x_m + s*np.random.normal(0,1)\n",
    "        x2 = y_m + s*np.random.normal(0,1)\n",
    "        x_test_positive.append((x1,x2))\n",
    "\n",
    "\n",
    "x_m, y_m, s = 0,0,2\n",
    "for i in range(60):\n",
    "        x1 = x_m + s*np.random.normal(0,1)\n",
    "        x2 = y_m + s*np.random.normal(0,1)\n",
    "        x_test_negative.append((x1,x2))\n",
    "        \n",
    "x_train = x_train_positive + x_train_negative\n",
    "y_train = len(x_train_positive)*[+1] + len(x_train_negative)*[-1]\n",
    "t = list(zip(x_train, y_train))\n",
    "random.shuffle(t)\n",
    "x_train, y_train = zip(*t)\n",
    "#Here our x_train and y_train Data is ready\n",
    "\n",
    "x_test = x_test_positive + x_test_negative\n",
    "y_test = len(x_test_positive)*[+1] + len(x_test_negative)*[-1]\n",
    "t = list(zip(x_test, y_test))\n",
    "random.shuffle(t)\n",
    "x_test, y_test = zip(*t)\n",
    "#Here our x_test and y_test Data is ready\n",
    "\n",
    "x_train = list(x_train)\n",
    "y_train = list(y_train)\n",
    "x_test = list(x_test)\n",
    "y_test = list(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = CP_Diff_Class(x_train,y_train,x_test)\n",
    "out2 = CP_DiffBySame(x_train,y_train,x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using Diff/Same Class is:  83.84615384615385\n",
      "Accuracy using Different Class is:  83.84615384615385\n"
     ]
    }
   ],
   "source": [
    "def Accuracy(y_pred,y_test):\n",
    "    count = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if(y_pred[i]==y_test[i]):\n",
    "            count+=1\n",
    "    return (count/len(y_pred))*100\n",
    "print(\"Accuracy using Diff/Same Class is: \",Accuracy(out1[0],y_test))\n",
    "print(\"Accuracy using Different Class is: \",Accuracy(out2[0],y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validity for Different Class method is:  0.46811509101585425\n",
      "Validity for Different/Same Class method is:  0.440281855549031\n"
     ]
    }
   ],
   "source": [
    "def Validity(output):\n",
    "    y_pred,p_values,other_pvalues = output[0],output[1],output[2]\n",
    "    p_true = [] #True label of Y's Pvalue\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_test[i] == y_pred[i]:\n",
    "            p_true.append(p_values[i])   \n",
    "        else:\n",
    "            p_true.append(other_pvalues[i])\n",
    "    return sum(p_true)/len(p_true)\n",
    "\n",
    "print(\"Validity for Different Class method is: \",Validity(out1))\n",
    "print(\"Validity for Different/Same Class method is: \",Validity(out2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficiency Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efficiency for Different Class method is:  0.6285378743394009\n",
      "Efficiency for Diff/Same Class method is:  0.5065179095713447\n"
     ]
    }
   ],
   "source": [
    "def Efficiency(output):\n",
    "    pvalues, other_pvalues = output[1], output[2]\n",
    "    s = [x + y for x, y in zip(pvalues, other_pvalues)]\n",
    "    return sum(s)/len(pvalues)\n",
    "\n",
    "print(\"Efficiency for Different Class method is: \",Efficiency(out1))\n",
    "print(\"Efficiency for Diff/Same Class method is: \",Efficiency(out2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Set Seed Value testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, random, math, sys\n",
    "from termcolor import colored, cprint\n",
    "\n",
    "set_seeds,Acc_1,Acc_2,Val_1,Val_2,Eff_1,Eff_2,Acc_1_avg,Acc_2_avg,Val_1_avg,Val_2_avg,Eff_1_avg,Eff_2_avg = ([] for i in range(13))\n",
    "\n",
    "for it in range(10):\n",
    "    random.seed(it)\n",
    "    set_seeds.append(it)\n",
    "    x_train_positive,x_train_negative,x_test_positive,x_test_negative=[],[],[],[]\n",
    "\n",
    "    x_m, y_m, s = 2,3,1\n",
    "    for i in range(60):\n",
    "            x1 = x_m + s*np.random.normal(0,1)\n",
    "            x2 = y_m + s*np.random.normal(0,1)\n",
    "            x_train_positive.append((x1,x2))\n",
    "\n",
    "    x_m, y_m, s = 0,0,2\n",
    "    for i in range(70):\n",
    "            x1 = x_m + s*np.random.normal(0,1)\n",
    "            x2 = y_m + s*np.random.normal(0,1)\n",
    "            x_train_negative.append((x1,x2))\n",
    "\n",
    "    x_m, y_m, s = 2,3,1\n",
    "    for i in range(70):\n",
    "            x1 = x_m + s*np.random.normal(0,1)\n",
    "            x2 = y_m + s*np.random.normal(0,1)\n",
    "            x_test_positive.append((x1,x2))\n",
    "\n",
    "\n",
    "    x_m, y_m, s = 0,0,2\n",
    "    for i in range(60):\n",
    "            x1 = x_m + s*np.random.normal(0,1)\n",
    "            x2 = y_m + s*np.random.normal(0,1)\n",
    "            x_test_negative.append((x1,x2))\n",
    "\n",
    "    x_train = x_train_positive + x_train_negative\n",
    "    y_train = len(x_train_positive)*[+1] + len(x_train_negative)*[-1]\n",
    "    t = list(zip(x_train, y_train))\n",
    "    random.shuffle(t)\n",
    "    x_train, y_train = zip(*t)\n",
    "\n",
    "    x_test = x_test_positive + x_test_negative\n",
    "    y_test = len(x_test_positive)*[+1] + len(x_test_negative)*[-1]\n",
    "    t = list(zip(x_test, y_test))\n",
    "    random.shuffle(t)\n",
    "    x_test, y_test = zip(*t)\n",
    "    x_train, y_train, x_test, y_test = list(x_train), list(y_train), list(x_test), list(y_test)\n",
    "\n",
    "    out1 = CP_Diff_Class(x_train,y_train,x_test)\n",
    "    A1 = Accuracy(out1[0],y_test)\n",
    "    Acc_1_avg.append(A1)\n",
    "    if(A1>=80): A1 = colored(A1, 'green', attrs=['reverse', 'blink'])\n",
    "    elif((A1>=60) & (A1<80)): A1 = colored(A1, 'yellow', attrs=['reverse', 'blink'])\n",
    "    else: A1 = colored(A1, 'red', attrs=['reverse', 'blink'])\n",
    "    Acc_1.append(A1)\n",
    "\n",
    "    out2 = CP_DiffBySame(x_train,y_train,x_test)\n",
    "    A2 = Accuracy(out2[0],y_test)\n",
    "    Acc_2_avg.append(A2)\n",
    "    if(A2>=80): A2 = colored(A2, 'green', attrs=['reverse', 'blink'])\n",
    "    elif((A2>=60) & (A2<80)): A2 = colored(A2, 'yellow', attrs=['reverse', 'blink'])\n",
    "    else: A2 = colored(A2, 'red', attrs=['reverse', 'blink'])\n",
    "    Acc_2.append(A2)\n",
    "\n",
    "    v1 = Validity(CP_Diff_Class(x_train,y_train,x_test))\n",
    "    Val_1_avg.append(v1)\n",
    "    if(v1>=0.48): v1 = colored(v1, 'green', attrs=['reverse', 'blink'])\n",
    "    else: v1 = colored(v1, 'red', attrs=['reverse', 'blink'])\n",
    "    Val_1.append(v1)\n",
    "\n",
    "    v2 = Validity(CP_DiffBySame(x_train,y_train,x_test))\n",
    "    Val_2_avg.append(v2)\n",
    "    if(v2>=0.48): v2 = colored(v2, 'green', attrs=['reverse', 'blink'])\n",
    "    else: v2 = colored(v2, 'red', attrs=['reverse', 'blink'])\n",
    "    Val_2.append(v2)\n",
    "\n",
    "    E1 = Efficiency(CP_Diff_Class(x_train,y_train,x_test))\n",
    "    Eff_1_avg.append(E1)\n",
    "    if(E1>=0.75): E1 = colored(E1, 'red', attrs=['reverse', 'blink'])\n",
    "    elif((E1<0.75) & (E1>=0.65)): E1 = colored(E1, 'yellow', attrs=['reverse', 'blink'])\n",
    "    else: E1 = colored(E1, 'green', attrs=['reverse', 'blink'])\n",
    "    Eff_1.append(E1)\n",
    "\n",
    "    E2 = Efficiency(CP_DiffBySame(x_train,y_train,x_test))\n",
    "    Eff_2_avg.append(E2)\n",
    "    if(E2>=0.75): E2 = colored(E2, 'red', attrs=['reverse', 'blink'])\n",
    "    elif((E2<0.75) & (E2>=0.65)): E2 = colored(E2, 'yellow', attrs=['reverse', 'blink'])\n",
    "    else: E2 = colored(E2, 'green', attrs=['reverse', 'blink'])\n",
    "    Eff_2.append(E2)    \n",
    "\n",
    "set_seeds.append(\"Average\")\n",
    "Acc_1.append(sum(Acc_1_avg)/len(Acc_1_avg))\n",
    "Acc_2.append(sum(Acc_2_avg)/len(Acc_2_avg))\n",
    "Val_1.append(sum(Val_1_avg)/len(Val_1_avg))\n",
    "Val_2.append(sum(Val_2_avg)/len(Val_2_avg))\n",
    "Eff_1.append(sum(Eff_1_avg)/len(Eff_1_avg))\n",
    "Eff_2.append(sum(Eff_2_avg)/len(Eff_2_avg))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation Table:\n",
      "1 stands for Method 1: Nearest Neighbours to Different Class\n",
      "2 stands for Method 2: Nearest Neighbours to Diff/Same Class\n",
      "\n",
      "╒═══════════════╤═════════════╤═════════════╤═════════════╤═════════════╤═══════════════╤═══════════════╕\n",
      "│ Seed Values   │  Accuracy1  │  Accuracy2  │  Validity1  │  Validity2  │  Efficiency1  │  Efficiency2  │\n",
      "╞═══════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═══════════════╪═══════════════╡\n",
      "│ 0             │   \u001b[5m\u001b[7m\u001b[32m82.3077\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m82.3077\u001b[0m   │  \u001b[5m\u001b[7m\u001b[31m0.444568\u001b[0m   │  \u001b[5m\u001b[7m\u001b[31m0.479213\u001b[0m   │   \u001b[5m\u001b[7m\u001b[33m0.656019\u001b[0m    │   \u001b[5m\u001b[7m\u001b[32m0.594363\u001b[0m    │\n",
      "├───────────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│ 1             │   \u001b[5m\u001b[7m\u001b[32m81.5385\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m81.5385\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.482149\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.494656\u001b[0m   │   \u001b[5m\u001b[7m\u001b[33m0.678215\u001b[0m    │    \u001b[5m\u001b[7m\u001b[32m0.6431\u001b[0m     │\n",
      "├───────────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│ 2             │   \u001b[5m\u001b[7m\u001b[32m86.9231\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m86.1538\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.498356\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.518144\u001b[0m   │   \u001b[5m\u001b[7m\u001b[33m0.713036\u001b[0m    │   \u001b[5m\u001b[7m\u001b[32m0.623429\u001b[0m    │\n",
      "├───────────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│ 3             │   \u001b[5m\u001b[7m\u001b[32m88.4615\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m89.2308\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.555432\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.532179\u001b[0m   │   \u001b[5m\u001b[7m\u001b[31m0.757957\u001b[0m    │   \u001b[5m\u001b[7m\u001b[32m0.599413\u001b[0m    │\n",
      "├───────────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│ 4             │   \u001b[5m\u001b[7m\u001b[32m88.4615\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m88.4615\u001b[0m   │  \u001b[5m\u001b[7m\u001b[31m0.462008\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.480916\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m0.602349\u001b[0m    │   \u001b[5m\u001b[7m\u001b[32m0.542043\u001b[0m    │\n",
      "├───────────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│ 5             │   \u001b[5m\u001b[7m\u001b[32m80.7692\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m81.5385\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.519436\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.537874\u001b[0m   │   \u001b[5m\u001b[7m\u001b[31m0.765062\u001b[0m    │   \u001b[5m\u001b[7m\u001b[33m0.656606\u001b[0m    │\n",
      "├───────────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│ 6             │   \u001b[5m\u001b[7m\u001b[32m87.6923\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m88.4615\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.513623\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m0.48485\u001b[0m   │   \u001b[5m\u001b[7m\u001b[33m0.701644\u001b[0m    │   \u001b[5m\u001b[7m\u001b[32m0.545684\u001b[0m    │\n",
      "├───────────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│ 7             │   \u001b[5m\u001b[7m\u001b[32m86.9231\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m86.9231\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.494245\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.522255\u001b[0m   │   \u001b[5m\u001b[7m\u001b[33m0.675455\u001b[0m    │   \u001b[5m\u001b[7m\u001b[32m0.598415\u001b[0m    │\n",
      "├───────────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│ 8             │   \u001b[5m\u001b[7m\u001b[32m81.5385\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m83.0769\u001b[0m   │   \u001b[5m\u001b[7m\u001b[31m0.46148\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.486494\u001b[0m   │   \u001b[5m\u001b[7m\u001b[33m0.696359\u001b[0m    │    \u001b[5m\u001b[7m\u001b[32m0.61239\u001b[0m    │\n",
      "├───────────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│ 9             │   \u001b[5m\u001b[7m\u001b[32m88.4615\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m87.6923\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.499119\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.535173\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m0.638462\u001b[0m    │   \u001b[5m\u001b[7m\u001b[32m0.621139\u001b[0m    │\n",
      "├───────────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│ Average       │   85.3077   │   85.5385   │  0.493042   │  0.507176   │   0.688456    │   0.603658    │\n",
      "╘═══════════════╧═════════════╧═════════════╧═════════════╧═════════════╧═══════════════╧═══════════════╛\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "print(\"\\nObservation Table:\")\n",
    "print(\"1 stands for Method 1: Nearest Neighbours to Different Class\")\n",
    "print(\"2 stands for Method 2: Nearest Neighbours to Diff/Same Class\\n\")\n",
    "\n",
    "print(tabulate({'Seed Values': set_seeds, 'Accuracy1': Acc_1,\n",
    "                'Accuracy2': Acc_2, 'Validity1': Val_1, 'Validity2': Val_2,\n",
    "               'Efficiency1': Eff_1, 'Efficiency2': Eff_2}, headers=\"keys\", tablefmt='fancy_grid', numalign='center'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing noise to data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "Noise,Acc_1,Acc_2,Val_1,Val_2,Eff_1,Eff_2= ([] for i in range(7))\n",
    "\n",
    "for it in range(1,10):\n",
    "    random.seed(3)\n",
    "    Noise.append(it)\n",
    "    x_train_positive,x_train_negative,x_test_positive,x_test_negative=[],[],[],[]\n",
    "\n",
    "    x_m, y_m, s = 2,3,1\n",
    "    for i in range(60):\n",
    "            x1 = x_m + s*np.random.normal(0,1)\n",
    "            x2 = y_m + s*np.random.normal(0,1)\n",
    "            x_train_positive.append((x1,x2))\n",
    "\n",
    "    x_m, y_m, s = 0,0,2\n",
    "    for i in range(70):\n",
    "            x1 = x_m + s*np.random.normal(0,1)\n",
    "            x2 = y_m + s*np.random.normal(0,1)\n",
    "            x_train_negative.append((x1,x2))\n",
    "\n",
    "    x_m, y_m, s = 2,3,1\n",
    "    for i in range(70):\n",
    "            x1 = x_m + s*np.random.normal(0,1)\n",
    "            x2 = y_m + s*np.random.normal(0,1)\n",
    "            x_test_positive.append((x1,x2))\n",
    "\n",
    "\n",
    "    x_m, y_m, s = 0,0,2\n",
    "    for i in range(60):\n",
    "            x1 = x_m + s*np.random.normal(0,1)\n",
    "            x2 = y_m + s*np.random.normal(0,1)\n",
    "            x_test_negative.append((x1,x2))\n",
    "\n",
    "    x_train = x_train_positive + x_train_negative\n",
    "    y_train = len(x_train_positive)*[+1] + len(x_train_negative)*[-1]\n",
    "    t = list(zip(x_train, y_train))\n",
    "    random.shuffle(t)\n",
    "    x_train, y_train = zip(*t)\n",
    "\n",
    "    x_test = x_test_positive + x_test_negative\n",
    "    y_test = len(x_test_positive)*[+1] + len(x_test_negative)*[-1]\n",
    "    t = list(zip(x_test, y_test))\n",
    "    random.shuffle(t)\n",
    "    x_test, y_test = zip(*t)\n",
    "\n",
    "    x_train, y_train, x_test, y_test = list(x_train), list(y_train), list(x_test), list(y_test)\n",
    "\n",
    "    out1 = CP_Diff_Class(x_train,y_train,x_test)\n",
    "    A1 = Accuracy(out1[0],y_test)\n",
    "    if(A1>=80): A1 = colored(A1, 'green', attrs=['reverse', 'blink'])\n",
    "    elif((A1>=60) & (A1<80)): A1 = colored(A1, 'yellow', attrs=['reverse', 'blink'])\n",
    "    else: A1 = colored(A1, 'red', attrs=['reverse', 'blink'])\n",
    "    Acc_1.append(A1)\n",
    "\n",
    "    out2 = CP_DiffBySame(x_train,y_train,x_test)\n",
    "    A2 = Accuracy(out2[0],y_test)\n",
    "    if(A2>=80): A2 = colored(A2, 'green', attrs=['reverse', 'blink'])\n",
    "    elif((A2>=60) & (A2<80)): A2 = colored(A2, 'yellow', attrs=['reverse', 'blink'])\n",
    "    else: A2 = colored(A2, 'red', attrs=['reverse', 'blink'])\n",
    "    Acc_2.append(A2)\n",
    "\n",
    "    v1 = Validity(CP_Diff_Class(x_train,y_train,x_test))\n",
    "    if(v1>=0.48): v1 = colored(v1, 'green', attrs=['reverse', 'blink'])\n",
    "    else: v1 = colored(v1, 'red', attrs=['reverse', 'blink'])\n",
    "    Val_1.append(v1)\n",
    "\n",
    "    v2 = Validity(CP_DiffBySame(x_train,y_train,x_test))\n",
    "    if(v2>=0.48): v2 = colored(v2, 'green', attrs=['reverse', 'blink'])\n",
    "    else: v2 = colored(v2, 'red', attrs=['reverse', 'blink'])\n",
    "    Val_2.append(v2)\n",
    "\n",
    "\n",
    "    E1 = Efficiency(CP_Diff_Class(x_train,y_train,x_test))\n",
    "    if(E1>=0.75): E1 = colored(E1, 'red', attrs=['reverse', 'blink'])\n",
    "    elif((E1<0.75) & (E1>=0.65)): E1 = colored(E1, 'yellow', attrs=['reverse', 'blink'])\n",
    "    else: E1 = colored(E1, 'green', attrs=['reverse', 'blink'])\n",
    "    Eff_1.append(E1)\n",
    "\n",
    "    E2 = Efficiency(CP_DiffBySame(x_train,y_train,x_test))\n",
    "    if(E2>=0.75): E2 = colored(E2, 'red', attrs=['reverse', 'blink'])\n",
    "    elif((E2<0.75) & (E2>=0.65)): E2 = colored(E2, 'yellow', attrs=['reverse', 'blink'])\n",
    "    else: E2 = colored(E2, 'green', attrs=['reverse', 'blink'])\n",
    "    Eff_2.append(E2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation Table after Introducing Noise to X_test(-1 Class):\n",
      "1 stands for Method 1: Nearest Neighbours to Different Class\n",
      "2 stands for Method 2: Nearest Neighbours to Diff/Same Class\n",
      "\n",
      "╒═════════╤═════════════╤═════════════╤═════════════╤═════════════╤═══════════════╤═══════════════╕\n",
      "│  Noise  │  Accuracy1  │  Accuracy2  │  Validity1  │  Validity2  │  Efficiency1  │  Efficiency2  │\n",
      "╞═════════╪═════════════╪═════════════╪═════════════╪═════════════╪═══════════════╪═══════════════╡\n",
      "│    1    │   \u001b[5m\u001b[7m\u001b[32m90.7692\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m90.7692\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.509865\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.521433\u001b[0m   │   \u001b[5m\u001b[7m\u001b[33m0.694656\u001b[0m    │   \u001b[5m\u001b[7m\u001b[32m0.576747\u001b[0m    │\n",
      "├─────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│    2    │     \u001b[5m\u001b[7m\u001b[32m80\u001b[0m      │     \u001b[5m\u001b[7m\u001b[32m80\u001b[0m      │   \u001b[5m\u001b[7m\u001b[32m0.51973\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.537639\u001b[0m   │   \u001b[5m\u001b[7m\u001b[31m0.790781\u001b[0m    │   \u001b[5m\u001b[7m\u001b[33m0.682501\u001b[0m    │\n",
      "├─────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│    3    │   \u001b[5m\u001b[7m\u001b[32m86.9231\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m86.9231\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.543042\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.528244\u001b[0m   │   \u001b[5m\u001b[7m\u001b[33m0.701351\u001b[0m    │   \u001b[5m\u001b[7m\u001b[32m0.591544\u001b[0m    │\n",
      "├─────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│    4    │   \u001b[5m\u001b[7m\u001b[32m84.6154\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m83.8462\u001b[0m   │  \u001b[5m\u001b[7m\u001b[31m0.468761\u001b[0m   │  \u001b[5m\u001b[7m\u001b[31m0.463476\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m0.615972\u001b[0m    │    \u001b[5m\u001b[7m\u001b[32m0.54909\u001b[0m    │\n",
      "├─────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│    5    │   \u001b[5m\u001b[7m\u001b[32m86.9231\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m86.9231\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.507927\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.494363\u001b[0m   │   \u001b[5m\u001b[7m\u001b[33m0.721844\u001b[0m    │    \u001b[5m\u001b[7m\u001b[32m0.60276\u001b[0m    │\n",
      "├─────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│    6    │     \u001b[5m\u001b[7m\u001b[32m90\u001b[0m      │   \u001b[5m\u001b[7m\u001b[32m87.6923\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.508749\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.541163\u001b[0m   │   \u001b[5m\u001b[7m\u001b[33m0.689019\u001b[0m    │   \u001b[5m\u001b[7m\u001b[32m0.623429\u001b[0m    │\n",
      "├─────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│    7    │   \u001b[5m\u001b[7m\u001b[32m82.3077\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m81.5385\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.494069\u001b[0m   │  \u001b[5m\u001b[7m\u001b[31m0.474516\u001b[0m   │    \u001b[5m\u001b[7m\u001b[33m0.74404\u001b[0m    │   \u001b[5m\u001b[7m\u001b[32m0.602349\u001b[0m    │\n",
      "├─────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│    8    │   \u001b[5m\u001b[7m\u001b[32m94.6154\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m92.3077\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.552261\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m0.5468\u001b[0m    │   \u001b[5m\u001b[7m\u001b[31m0.763183\u001b[0m    │   \u001b[5m\u001b[7m\u001b[32m0.598356\u001b[0m    │\n",
      "├─────────┼─────────────┼─────────────┼─────────────┼─────────────┼───────────────┼───────────────┤\n",
      "│    9    │   \u001b[5m\u001b[7m\u001b[32m88.4615\u001b[0m   │   \u001b[5m\u001b[7m\u001b[32m89.2308\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.520376\u001b[0m   │  \u001b[5m\u001b[7m\u001b[32m0.552378\u001b[0m   │   \u001b[5m\u001b[7m\u001b[33m0.742924\u001b[0m    │   \u001b[5m\u001b[7m\u001b[32m0.640575\u001b[0m    │\n",
      "╘═════════╧═════════════╧═════════════╧═════════════╧═════════════╧═══════════════╧═══════════════╛\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "print(\"\\nObservation Table after Introducing Noise to X_test(-1 Class):\")\n",
    "print(\"1 stands for Method 1: Nearest Neighbours to Different Class\")\n",
    "print(\"2 stands for Method 2: Nearest Neighbours to Diff/Same Class\\n\")\n",
    "\n",
    "\n",
    "print(tabulate({'Noise': Noise, 'Accuracy1': Acc_1,\n",
    "                'Accuracy2': Acc_2, 'Validity1': Val_1, 'Validity2': Val_2,\n",
    "               'Efficiency1': Eff_1, 'Efficiency2': Eff_2}, headers=\"keys\", tablefmt='fancy_grid', numalign='center'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphical Representation of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(3)\n",
    "x_train_positive=[]\n",
    "x_m = 2\n",
    "y_m = 3\n",
    "s = 1 \n",
    "for i in range(1000):\n",
    "        x1 = x_m + s*np.random.normal(0,1)\n",
    "        x2 = y_m + s*np.random.normal(0,1)\n",
    "        x_train_positive.append((x1,x2))\n",
    "\n",
    "x_train_negative=[]\n",
    "x_m = 0\n",
    "y_m = 0\n",
    "s = 1.2\n",
    "for i in range(1000):\n",
    "        x1 = x_m + s*np.random.normal(0,1)\n",
    "        x2 = y_m + s*np.random.normal(0,1)\n",
    "        x_train_negative.append((x1,x2))\n",
    "\n",
    "\n",
    "x_train = x_train_positive + x_train_negative\n",
    "y_train = len(x_train_positive)*[+1] + len(x_train_negative)*[-1]\n",
    "x1 = [x_train_positive[i][0] for i in range(len(x_train_positive))]\n",
    "x2 = [x_train_positive[i][1] for i in range(len(x_train_positive))]\n",
    "plt.scatter(x1,x2,c=\"red\")\n",
    "plt.text(2,3,\"Class +1\")\n",
    "p1 = [x_train_negative[i][0] for i in range(len(x_train_negative))]\n",
    "p2 = [x_train_negative[i][1] for i in range(len(x_train_negative))]\n",
    "plt.scatter(p1,p2,c=\"green\")\n",
    "plt.text(0,0,\"Class -1\")\n",
    "plt.title(\"Points for classes -1 and +1\")\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96eb50e1d44aed467dc8f759cb08c32fbfa9babcf79c554e2d0e5feb04653a10"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
